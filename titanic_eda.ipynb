{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can identifying families with children help boost the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classificiation purpose in the data competition, the value of demographic information implied by the ticket combination in the Kaggle Titanic data set (hereafter, the Titanic data) is widely understated. In this post, I'm going to show you how to expose demographic information hidden in the full data set (the join of the training set and test set) of the Titanic data, and hopefully help us boost our prediction accuracy.\n",
    "\n",
    "Note: If you are concerned about data leakage that araises in data processing before splitting the data set, you may find this [discussion](https://www.kaggle.com/c/titanic/discussion/41928#235524) interesting. For the purose that is more of winning the competition than generalization, I'll simply use the full data set as the basis of feature eningeering and leave the data leakage judgement for you.\n",
    "\n",
    "Here is a list of observations I'm going to point out with advanced tricks of Pandas in conjunction with NumPy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Library we need \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure Visualization Defaults\n",
    "mpl.style.use('ggplot')\n",
    "pylab.rcParams['figure.figsize'] = 12, 8\n",
    "sns.set_style('white')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace the following two directories with those in the following comments\n",
    "df_train = pd.read_csv(r'F:\\GitHubData\\Titanic\\train.csv') # r\"../input/train.csv\"\n",
    "df_test = pd.read_csv(r'F:\\GitHubData\\Titanic\\test.csv') # r\"../input/test.csv\"\n",
    "\n",
    "# inconsistent columns so we \n",
    "# use concat, rather than pd.merge(df_train, df_test, on = [...], how = 'inner')\n",
    "df_all = pd.concat([df_train, df_test], join='outer', axis=0) \n",
    "df_train.name = 'Training data'\n",
    "df_test.name = 'Test data'\n",
    "\n",
    "# We have 11 features and 1 target variables\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples: 891\n",
      "Number of Test Examples = 418\n",
      "Shape of Training Examples = (891, 12)\n",
      "Shape of Test Examples = (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Dimensions\n",
    "print(f'Number of Training Examples: {df_train.shape[0]}')\n",
    "print(f'Number of Test Examples = {df_test.shape[0]}')\n",
    "print(f'Shape of Training Examples = {df_train.shape}')\n",
    "print(f'Shape of Test Examples = {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket']\n",
      "['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket']\n"
     ]
    }
   ],
   "source": [
    "# Column name we have\n",
    "print(sorted(df_train.columns.tolist())) \n",
    "print(sorted(df_test.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             count        mean         std   min       25%       50%    75%  \\\n",
      "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
      "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
      "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
      "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
      "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
      "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
      "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
      "\n",
      "                  max  \n",
      "PassengerId  891.0000  \n",
      "Survived       1.0000  \n",
      "Pclass         3.0000  \n",
      "Age           80.0000  \n",
      "SibSp          8.0000  \n",
      "Parch          6.0000  \n",
      "Fare         512.3292  \n",
      "------------------------------\n",
      "         count unique                       top freq\n",
      "Name       891    891  Mannion, Miss. Margareth    1\n",
      "Sex        891      2                      male  577\n",
      "Ticket     891    681                  CA. 2343    7\n",
      "Cabin      204    147               C23 C25 C27    4\n",
      "Embarked   889      3                         S  644\n"
     ]
    }
   ],
   "source": [
    "# Numeric variables in training set\n",
    "print(df_train.describe(include=[np.number]).T)\n",
    "print('-' * 30)\n",
    "# Categorical variables in training set\n",
    "print(df_train.describe(include=['O']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "PassengerId NO. missing values: 0\n",
      "Survived    NO. missing values: 0\n",
      "Pclass      NO. missing values: 0\n",
      "Name        NO. missing values: 0\n",
      "Sex         NO. missing values: 0\n",
      "Age         NO. missing values: 177\n",
      "SibSp       NO. missing values: 0\n",
      "Parch       NO. missing values: 0\n",
      "Ticket      NO. missing values: 0\n",
      "Fare        NO. missing values: 0\n",
      "Cabin       NO. missing values: 687\n",
      "Embarked    NO. missing values: 2\n",
      "------------------------------\n",
      "Test data\n",
      "PassengerId NO. missing values: 0\n",
      "Pclass      NO. missing values: 0\n",
      "Name        NO. missing values: 0\n",
      "Sex         NO. missing values: 0\n",
      "Age         NO. missing values: 86\n",
      "SibSp       NO. missing values: 0\n",
      "Parch       NO. missing values: 0\n",
      "Ticket      NO. missing values: 0\n",
      "Fare        NO. missing values: 1\n",
      "Cabin       NO. missing values: 327\n",
      "Embarked    NO. missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "def displayMissing(df):\n",
    "    for col in df.columns.tolist():\n",
    "        print(f'{col:11s} NO. missing values: {df[col].isnull().sum()}')\n",
    "\n",
    "for i, df in enumerate([df_train, df_test]):\n",
    "    print(f'{df.name}')\n",
    "    displayMissing(df)\n",
    "    if i == 0: print('-' * 30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pointed out in many exploratory data analysis on Kaggle Titanic data set, we have missing values in continuous features `Age` and `Fare` and nominal variables `Embarked` and `Cabin`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticket combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_num</th>\n",
       "      <th>Ticket_alp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Ticket_num Ticket_alp  \n",
       "0      0         A/5 21171   7.2500   NaN        S      21171        A/5  \n",
       "1      0          PC 17599  71.2833   C85        C      17599         PC  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S    3101282   STON/O2.  \n",
       "3      0            113803  53.1000  C123        S     113803          M  \n",
       "4      0            373450   8.0500   NaN        S     373450          M  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo:  Ticket combination is the feature without any missing values.\n",
    "# We should try to extract any information from it\n",
    "# although it appears useless at the first glance.\n",
    "def getTicketPrefixAndNumber(df, col):\n",
    "    # naming the columns to be created\n",
    "    col_num = col + '_num'\n",
    "    col_alp = col + '_alp'\n",
    "\n",
    "    # get the last group of contiguous digits\n",
    "    # vectorize string function with str method\n",
    "    # get any contignuous nuemrical digits from the end\n",
    "    # return anything that matches the pattern specified inside the parenthesis \n",
    "    df[col_num] = df[col].str.extract(r'(\\d+)$')\n",
    "    df[col_num].fillna(-1, inplace=True)\n",
    "\n",
    "    # get the complete string before a space that is followed by a trailing number group\n",
    "    df[col_alp] = df[col].str.extract(r'(.*)\\ \\d+$')\n",
    "    # sidenote: .replace({'\\.': '', '/': ''}, regex=True)\n",
    "    df[col_alp].fillna('M', inplace=True)\n",
    "    return df\n",
    "\n",
    "getTicketPrefixAndNumber(df_all, 'Ticket').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1309\n",
      "unique     924\n",
      "top       2343\n",
      "freq        11\n",
      "Name: Ticket_num, dtype: object\n",
      "------------------------------\n",
      "count    1.309000e+03\n",
      "mean     2.830713e+05\n",
      "std      6.353943e+05\n",
      "min     -1.000000e+00\n",
      "25%      1.356700e+04\n",
      "50%      1.108130e+05\n",
      "75%      3.470750e+05\n",
      "max      3.101317e+06\n",
      "Name: Ticket_num, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_all.Ticket_num.describe())\n",
    "print('-' * 30) \n",
    "df_all['Ticket_num'] = pd.to_numeric(df_all['Ticket_num'])\n",
    "print(df_all.Ticket_num.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Ticket_num</th>\n",
       "      <th>Ticket_alp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC 17599</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113803</td>\n",
       "      <td>113803</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373450</td>\n",
       "      <td>373450</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ticket  Ticket_num Ticket_alp\n",
       "0         A/5 21171       21171        A/5\n",
       "1          PC 17599       17599         PC\n",
       "2  STON/O2. 3101282     3101282   STON/O2.\n",
       "3            113803      113803          M\n",
       "4            373450      373450          M"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if the string decomposition works as expected.\n",
    "colnames = ['Ticket' + s for s in ['', '_num', '_alp']]\n",
    "df_all[colnames].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Travel group\n",
    "Are there any people sharing the same ticket number but actually come from different travel groups (identified by ticket combination)? The answer is Yes. In such a case, I use `Ticket`, rather than `Ticket_num` to define a travel group. Using `last name` to define a travel group as seen in many kernels is not good enough for my purpose. People travelling together as a group should bear similar characteristics related to their survival rates in this travel disaster. Members of a travel group do not necessary share biological relathinship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_num</th>\n",
       "      <th>Ticket_alp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mellors, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SW/PP 751</td>\n",
       "      <td>10.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>751</td>\n",
       "      <td>SW/PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Willey, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O./P.P. 751</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>751</td>\n",
       "      <td>S.O./P.P.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Harris, Mr. George</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.W./PP 752</td>\n",
       "      <td>10.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>752</td>\n",
       "      <td>S.W./PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Duquemin, Mr. Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O./P.P. 752</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>752</td>\n",
       "      <td>S.O./P.P.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Abbott, Mrs. Stanton (Rosa Hunt)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>20.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2673</td>\n",
       "      <td>C.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Abbott, Mr. Rossmore Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>20.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2673</td>\n",
       "      <td>C.A.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
       "226          227       1.0       2         Mellors, Mr. William John    male   \n",
       "648          649       0.0       3                Willey, Mr. Edward    male   \n",
       "570          571       1.0       2                Harris, Mr. George    male   \n",
       "155         1047       NaN       3              Duquemin, Mr. Joseph    male   \n",
       "279          280       1.0       3  Abbott, Mrs. Stanton (Rosa Hunt)  female   \n",
       "746          747       0.0       3       Abbott, Mr. Rossmore Edward    male   \n",
       "\n",
       "      Age  SibSp  Parch         Ticket   Fare Cabin Embarked  Ticket_num  \\\n",
       "226  19.0      0      0      SW/PP 751  10.50   NaN        S         751   \n",
       "648   NaN      0      0  S.O./P.P. 751   7.55   NaN        S         751   \n",
       "570  62.0      0      0    S.W./PP 752  10.50   NaN        S         752   \n",
       "155  24.0      0      0  S.O./P.P. 752   7.55   NaN        S         752   \n",
       "279  35.0      1      1      C.A. 2673  20.25   NaN        S        2673   \n",
       "746  16.0      1      1      C.A. 2673  20.25   NaN        S        2673   \n",
       "\n",
       "    Ticket_alp  \n",
       "226      SW/PP  \n",
       "648  S.O./P.P.  \n",
       "570    S.W./PP  \n",
       "155  S.O./P.P.  \n",
       "279       C.A.  \n",
       "746       C.A.  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "islice = df_all.groupby('Ticket_num')['Ticket_alp'].transform(lambda x: x.nunique() > 1)\n",
    "df_all.loc[islice,:].sort_values(by=['Ticket_num']).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival rate\n",
    "Check to see if survival rate (based on available Survived feature) varies across ticket combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtb1 = df_all[['Survived', 'Ticket']].groupby(['Ticket'])\n",
    "# compute the groupwise survival rates (percentage) # pd.count() counts non-NA cells\n",
    "temp = (gtb1['Survived'].sum() / gtb1['Survived'].count() * 100).sort_values()\n",
    "# name the resulting column to be used in the merge below\n",
    "temp.name = 'TeamSurvivalRate'\n",
    "# one-to-many merge on column Ticket\n",
    "df_all = pd.merge(df_all, temp, on='Ticket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of family and travel group\n",
    "Check if there exist travel groups with members of size larger than 5.\n",
    "\n",
    "Note: `pd.count()` doesn't count NA cells. If use it rather than `pd.size()` to count group size on Survived feature, the resulting group size is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['347082', '382652', '347077', '19950', '3101295', 'CA 2144',\n",
       "       '347088', 'S.O.C. 14879', '1601', 'CA. 2343', '113781', 'PC 17608'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[df_all.groupby('Ticket')['Survived'].transform('size') > 5, :]['Ticket'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the travel group of ticket combination `S.O.C. 14879` has more than five members (two of which have unknown Survived features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticket  Survived\n",
       "149  S.O.C. 14879       0.0\n",
       "150  S.O.C. 14879       0.0\n",
       "151  S.O.C. 14879       0.0\n",
       "152  S.O.C. 14879       0.0\n",
       "153  S.O.C. 14879       0.0\n",
       "154  S.O.C. 14879       NaN\n",
       "155  S.O.C. 14879       NaN"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[df_all.Ticket=='S.O.C. 14879',['Ticket', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the family of ticket combination `PC 17608` travles in a group with two other non-biological relationship members `PassengerId` = 951 and 1267."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_num</th>\n",
       "      <th>Ticket_alp</th>\n",
       "      <th>TeamSurvivalRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Susan Parker \"Suzette\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Mrs. Arthur Larned (Emily Maria Borie)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Chaudanson, Miss. Victorine</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B61</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Master. John Borie</td>\n",
       "      <td>male</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Mr. Arthur Larned</td>\n",
       "      <td>male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Bowen, Miss. Grace Scott</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>17608</td>\n",
       "      <td>PC</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "504          312       1.0       1   \n",
       "505          743       1.0       1   \n",
       "506          916       NaN       1   \n",
       "507          951       NaN       1   \n",
       "508          956       NaN       1   \n",
       "509         1034       NaN       1   \n",
       "510         1267       NaN       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "504                       Ryerson, Miss. Emily Borie  female  18.0      2   \n",
       "505            Ryerson, Miss. Susan Parker \"Suzette\"  female  21.0      2   \n",
       "506  Ryerson, Mrs. Arthur Larned (Emily Maria Borie)  female  48.0      1   \n",
       "507                      Chaudanson, Miss. Victorine  female  36.0      0   \n",
       "508                      Ryerson, Master. John Borie    male  13.0      2   \n",
       "509                       Ryerson, Mr. Arthur Larned    male  61.0      1   \n",
       "510                         Bowen, Miss. Grace Scott  female  45.0      0   \n",
       "\n",
       "     Parch    Ticket     Fare            Cabin Embarked  Ticket_num  \\\n",
       "504      2  PC 17608  262.375  B57 B59 B63 B66        C       17608   \n",
       "505      2  PC 17608  262.375  B57 B59 B63 B66        C       17608   \n",
       "506      3  PC 17608  262.375  B57 B59 B63 B66        C       17608   \n",
       "507      0  PC 17608  262.375              B61        C       17608   \n",
       "508      2  PC 17608  262.375  B57 B59 B63 B66        C       17608   \n",
       "509      3  PC 17608  262.375  B57 B59 B63 B66        C       17608   \n",
       "510      0  PC 17608  262.375              NaN        C       17608   \n",
       "\n",
       "    Ticket_alp  TeamSurvivalRate  \n",
       "504         PC             100.0  \n",
       "505         PC             100.0  \n",
       "506         PC             100.0  \n",
       "507         PC             100.0  \n",
       "508         PC             100.0  \n",
       "509         PC             100.0  \n",
       "510         PC             100.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[df_all['Ticket'] == 'PC 17608',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, here is the biggest family/group in the Titanic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_num</th>\n",
       "      <th>Ticket_alp</th>\n",
       "      <th>TeamSurvivalRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Master. Thomas Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Constance Gladys</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. George John Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Ada</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Master. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mrs. John (Annie Bullen)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2343</td>\n",
       "      <td>CA.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "283          160       0.0       3         Sage, Master. Thomas Henry    male   \n",
       "284          181       0.0       3       Sage, Miss. Constance Gladys  female   \n",
       "285          202       0.0       3                Sage, Mr. Frederick    male   \n",
       "286          325       0.0       3           Sage, Mr. George John Jr    male   \n",
       "287          793       0.0       3            Sage, Miss. Stella Anna  female   \n",
       "288          847       0.0       3           Sage, Mr. Douglas Bullen    male   \n",
       "289          864       0.0       3  Sage, Miss. Dorothy Edith \"Dolly\"  female   \n",
       "290         1080       NaN       3                    Sage, Miss. Ada  female   \n",
       "291         1234       NaN       3              Sage, Mr. John George    male   \n",
       "292         1252       NaN       3        Sage, Master. William Henry    male   \n",
       "293         1257       NaN       3     Sage, Mrs. John (Annie Bullen)  female   \n",
       "\n",
       "      Age  SibSp  Parch    Ticket   Fare Cabin Embarked  Ticket_num  \\\n",
       "283   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "284   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "285   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "286   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "287   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "288   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "289   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "290   NaN      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "291   NaN      1      9  CA. 2343  69.55   NaN        S        2343   \n",
       "292  14.5      8      2  CA. 2343  69.55   NaN        S        2343   \n",
       "293   NaN      1      9  CA. 2343  69.55   NaN        S        2343   \n",
       "\n",
       "    Ticket_alp  TeamSurvivalRate  \n",
       "283        CA.               0.0  \n",
       "284        CA.               0.0  \n",
       "285        CA.               0.0  \n",
       "286        CA.               0.0  \n",
       "287        CA.               0.0  \n",
       "288        CA.               0.0  \n",
       "289        CA.               0.0  \n",
       "290        CA.               0.0  \n",
       "291        CA.               0.0  \n",
       "292        CA.               0.0  \n",
       "293        CA.               0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[df_all['Ticket'] == 'CA. 2343',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['347082', '3101295', 'CA 2144', '347088', '1601', 'CA. 2343'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If use it rather than `pd.size()` to count group size on Survived feature, \n",
    "# the resulting group size is not correct.\n",
    "df_all.loc[df_all.groupby('Ticket')['Survived'].transform('count') > 5, :]['Ticket'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trave group varies in size. I create a feature `TeamSize` to count the total number of people in a group of the same ticket comibnation. For the estimate of family size, it is pretty straightforward to account for the entry itself in addition to the number of its siblings, parents and childrens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['TeamSize'] = df_all.groupby('Ticket')['Survived'].transform(lambda x: x.shape[0]) # ~ x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct size of a family\n",
    "df_all['FamilySize'] = df_all['SibSp'] + df_all['Parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than $76\\%$ of travel groups are composed of one person only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Group Size</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Percentage</th>\n",
       "      <td>76.749193</td>\n",
       "      <td>14.208827</td>\n",
       "      <td>5.274489</td>\n",
       "      <td>1.722282</td>\n",
       "      <td>0.753498</td>\n",
       "      <td>0.538213</td>\n",
       "      <td>0.430571</td>\n",
       "      <td>0.215285</td>\n",
       "      <td>0.107643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Group Size         1          2         3         4         5         7   \\\n",
       "Percentage  76.749193  14.208827  5.274489  1.722282  0.753498  0.538213   \n",
       "\n",
       "Group Size        6         8         11  \n",
       "Percentage  0.430571  0.215285  0.107643  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have a sense of the distribution of TeamSize\n",
    "g = df_all.groupby(['Ticket']).first()['TeamSize'].value_counts()\n",
    "ans = g / g.sum() * 100 # convert to percentrage\n",
    "# Tabularize\n",
    "ans.index = ans.index.astype(int)\n",
    "ans.index.name = 'Group Size'\n",
    "pd.DataFrame(ans).rename(columns={'TeamSize': 'Percentage'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows that team size might be a useful predictor for survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TeamSize\n",
       "1.0     27.027027\n",
       "2.0     50.847458\n",
       "3.0     65.248227\n",
       "4.0     68.750000\n",
       "5.0     39.285714\n",
       "6.0     25.000000\n",
       "7.0     35.000000\n",
       "8.0     35.714286\n",
       "11.0     0.000000\n",
       "Name: TeamSurvivalRate, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby(['TeamSize','Ticket'])['TeamSurvivalRate'].mean().groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  TeamSize\n",
       "1       1.0          44.444444\n",
       "        2.0          65.217391\n",
       "        3.0          76.666667\n",
       "        4.0          80.208333\n",
       "        5.0          58.333333\n",
       "        6.0          50.000000\n",
       "        7.0         100.000000\n",
       "2       1.0          38.202247\n",
       "        2.0          51.515152\n",
       "        3.0          72.222222\n",
       "        4.0          70.833333\n",
       "        5.0         100.000000\n",
       "        7.0           0.000000\n",
       "3       1.0          20.000000\n",
       "        2.0          33.333333\n",
       "        3.0          52.500000\n",
       "        4.0          43.750000\n",
       "        5.0           0.000000\n",
       "        6.0           0.000000\n",
       "        7.0          25.000000\n",
       "        8.0          35.714286\n",
       "        11.0          0.000000\n",
       "Name: TeamSurvivalRate, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby(['Pclass', 'TeamSize'])['TeamSurvivalRate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the estimated group survival rate, regardless of passenger class, the top three groups tend to include groups of size four and three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  TeamSize  TeamSurvivalRate\n",
      "0        1       1.0         44.444444\n",
      "5        1       6.0         50.000000\n",
      "4        1       5.0         58.333333\n",
      "1        1       2.0         65.217391\n",
      "2        1       3.0         76.666667\n",
      "3        1       4.0         80.208333\n",
      "6        1       7.0        100.000000\n",
      "12       2       7.0          0.000000\n",
      "7        2       1.0         38.202247\n",
      "8        2       2.0         51.515152\n",
      "10       2       4.0         70.833333\n",
      "9        2       3.0         72.222222\n",
      "11       2       5.0        100.000000\n",
      "17       3       5.0          0.000000\n",
      "18       3       6.0          0.000000\n",
      "21       3      11.0          0.000000\n",
      "13       3       1.0         20.000000\n",
      "19       3       7.0         25.000000\n",
      "14       3       2.0         33.333333\n",
      "20       3       8.0         35.714286\n",
      "16       3       4.0         43.750000\n",
      "15       3       3.0         52.500000\n"
     ]
    }
   ],
   "source": [
    "# This code results in the sorting of Teamsize within passenger class by team survival rate.\n",
    "print(df_all.groupby(['Pclass', 'TeamSize'])['TeamSurvivalRate'].mean(). \\\n",
    "    reset_index().sort_values(by=['Pclass','TeamSurvivalRate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  TeamSize  TeamSurvivalRate\n",
      "2        1       3.0         76.666667\n",
      "3        1       4.0         80.208333\n",
      "6        1       7.0        100.000000\n",
      "10       2       4.0         70.833333\n",
      "9        2       3.0         72.222222\n",
      "11       2       5.0        100.000000\n",
      "20       3       8.0         35.714286\n",
      "16       3       4.0         43.750000\n",
      "15       3       3.0         52.500000\n"
     ]
    }
   ],
   "source": [
    "# We can further obtain the class-wise top three groups in terms of team survival rate.\n",
    "# Just append \"groupby(['Pclass']).tail(3)\".\n",
    "print(df_all.groupby(['Pclass', 'TeamSize'])['TeamSurvivalRate'].mean(). \\\n",
    "    reset_index().sort_values(by=['Pclass','TeamSurvivalRate']).groupby(['Pclass']).tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credibility of group survival rate\n",
    "The credibility of a group survival rate is measured in terms of the proportion of valid `Survived` feature. I will use it as a weight to adjust the `TeamSurvivalRate` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCredibilitySurvivalRate(df):\n",
    "    # Use `size` or `shape[0]` to get the full length of a series\n",
    "    # When summing over cells of {0,1,NaN}, \n",
    "    # regardless of the use of `pd.notnull()`, the outcome is identical.\n",
    "    df['SRcredibility'] = pd.notnull(df['Survived']).sum() / df['Survived'].size \n",
    "    return df\n",
    "\n",
    "df_all = df_all.groupby('Ticket').apply(getCredibilitySurvivalRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of family roles\n",
    "For flexibility in tuning hyper parameters like the age threshold for the definition of a child, I introduce the `cutoff` argument for the maximum child age and set the default cutoff age to 7. Then I do something like a grid search on the integer interval $[1, 29]$ to see the impact of the cutoff age configuratio on the estimate of survival rates by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRole(df, cutoff=7):\n",
    "    df['Role'] = 'Man'\n",
    "    df.loc[df['Sex'] == 'female', 'Role'] = 'Woman'\n",
    "    df.loc[df['Age'] <= cutoff, 'Role'] = 'Child'\n",
    "    return df\n",
    "\n",
    "ans = []\n",
    "ages = range(1, 30)\n",
    "for cut in ages:\n",
    "    getRole(df_all, cutoff=cut)\n",
    "    g = df_all.groupby(['Role'])\n",
    "    # [1] I covert the resulting Pandas series to a data frame object and then append\n",
    "    # it to the `ans` list object so that I can concatenate them in one step. later.\n",
    "    ans.append((g['Survived'].sum() / g['Survived'].count()).to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] To concatnate the data frames stored in the `ans` list object.\n",
    "temp = pd.concat(ans, axis=1)  # 3 by N (=len(ages))\n",
    "# [3] convert 3 by N table to N by 3 table\n",
    "tb1 = pd.DataFrame(np.array(temp).T,\n",
    "                   columns=['Child', 'Man', 'Woman'], index=ages)  # N by 3\n",
    "tb1.index.name = 'Age'\n",
    "# [4] melt the table tb1 for drawing a line plot\n",
    "tb1.reset_index(inplace=True)  # prep for melt\n",
    "tb2 = pd.melt(tb1, id_vars=['Age'], value_vars=['Child', 'Man', 'Woman'],\n",
    "              var_name='Role', value_name='Survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm going to use seaborn facetGrid for drawing the line plot ([searborn.FaceGrid](https://seaborn.pydata.org/generated/seaborn.FacetGrid.html) document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [5] FacetGrid and mapping plot functions to each grid\n",
    "g = sns.FacetGrid(tb2, col='Role', margin_titles=True)\n",
    "g = g.map(plt.plot, 'Age', 'Survival')\n",
    "\n",
    "# add vertical line\n",
    "axes = g.fig.axes\n",
    "for ax in axes:\n",
    "    ax.vlines(x=15, ymax=1, ymin=0, linestyles='dashed', alpha=0.3, colors='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The child survival rate is trending downward as the maximum age of children is lowered. I want to maximize the number of children with the constraint to maintain the child survival rate at least $60\\%$, so I set the hyper parameter of child age to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRole(df_all, cutoff=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adults traveling with children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as an example: df_all.loc[df_all['Ticket_num']==17608,:]\n",
    "# Step 1. Create a new column for the number of siblings of a child.\n",
    "df_all['childSibSp'] = np.where(df_all['Role'] == 'Child', df_all['SibSp'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37\n",
       "Name: childSibSp, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2. Is the childSibSp value unique within a travel group? Answer: Yes\n",
    "logic = df_all['childSibSp']>0 # screen out parents (whose SibSp is at least one) \n",
    "df_all.loc[logic,:].groupby('Ticket')['childSibSp'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, We can use childSibSp to identify siblings of a child."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop here! ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Broadcasting: in a group, let every entry can see the shared 'childSibSp' value.\n",
    "df_all['childSibSp'] = df_all.groupby('Ticket')['childSibSp'].transform('max')\n",
    "# 'cz otherwise it's 0 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. If an example's SibSp equals to the shared value, the example must\n",
    "# from a elder child of age greater than the age limit for the child definition.\n",
    "logic = (df_all['SibSp'] != 0) & \\\n",
    "        (df_all['SibSp'] == df_all['childSibSp']) &\\\n",
    "        (df_all['Role'] != 'Child')\n",
    "df_all.loc[logic, 'Role'] = 'olderChild'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# todo: who is the female household head and/or the male household head?\n",
    "# Step 1. Identify the FamilySize value of the youngest child in each travel team.\n",
    "df_all['childFamilySize'] = np.where(df_all['Role'].isin(['Child', 'olderChild']),\n",
    "                                     df_all['FamilySize'], 0)\n",
    "# Step 2. Broadcasting the FamilySize value of the youngest child to\n",
    "# other members in the same travel team\n",
    "df_all['childFamilySize'] = df_all.groupby('Ticket')['childFamilySize'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Step 3. identy people who are parents\n",
    "def isMotherOrFather(s):\n",
    "    return 'Father' if s == 'Man' else 'Mother'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_logic = ((df_all['FamilySize'] == df_all['childFamilySize']) & \\\n",
    "               (~df_all['Role'].isin(['Child', 'olderChild'])) & \\\n",
    "               (df_all['FamilySize'] > 0))\n",
    "# a trick to obtain the index of valid examples after logical operations\n",
    "slice_index = df_all.loc[slice_logic, :].index\n",
    "df_all.loc[slice_index, 'Role'] = \\\n",
    "    df_all.loc[slice_logic, :]['Role'].apply(isMotherOrFather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ChildWAdult'] = 'Not Applicable'\n",
    "logic = (df_all['Role'].isin(['Child', 'olderChild']))\n",
    "df_all.loc[logic, 'ChildWAdult'] = np.where(\n",
    "    df_all.loc[logic, 'FamilySize'] > df_all.loc[logic, 'childSibSp'] + 1,\n",
    "    'Yes',\n",
    "    'No'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of children per travel group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: How many children in this group?\n",
    "#Method 1.\n",
    "df_all['NumChild'] = df_all.groupby('Ticket')['Role'].\\\n",
    "    transform(lambda x: x.isin(['Child', 'olderChild']).sum())\n",
    "df_all['NumYoungChild'] = df_all.groupby('Ticket')['Role'].\\\n",
    "    transform(lambda x: x.isin(['Child']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Method 2.\n",
    "numChildDict = df_all.groupby('Ticket')['Age']\\\n",
    "    .apply(lambda x: (x <= cutoffChildAge).sum()).reset_index(name='NumChild')\n",
    "df_all.join(numChildDict, on='Ticket')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the survival rate by number of child varies, the highest survival rate\n",
    "# falls in family of three children and it holds across classes.\n",
    "print(df_all.groupby(['Pclass', 'NumChild'])['Survived'].mean())\n",
    "# So, number of children should be another good predictor;\n",
    "# In passenger classes 1 and 2, families with three children have higher\n",
    "# estimated survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: travel with dad, mom, or both? Is with mother better than with father? NO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works\n",
    "Note: if you move ['Role'] inside transform's lambda function, it fails.\n",
    "Below I compare two different approaches for completing similar logical\n",
    "operation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The usual method for broadcasting simple logical operations.\n",
    "df_all['hasMother'] = df_all.groupby('Ticket')['Role'].\\\n",
    "    transform(lambda x: (x == 'Mother').sum() > 0)\n",
    "df_all['hasFather'] = df_all.groupby('Ticket')['Role'].\\\n",
    "    transform(lambda x: (x == 'Father').sum() > 0)\n",
    "df_all['hasBothParents'] = np.where(\n",
    "    df_all['hasMother'] & df_all['hasFather'],\n",
    "    True,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Advanced Method: more complicated logical operations\n",
    "logics = [(df_all['hasFather'] & ~df_all['hasMother'], 'with Father'),\n",
    "          (df_all['hasFather'] & df_all['hasMother'], 'with Both'),\n",
    "          (~df_all['hasFather'] & df_all['hasMother'], 'with Mother'),\n",
    "          (~df_all['hasFather'] & ~df_all['hasMother'], 'without Parents')]\n",
    "for logic, s in logics:\n",
    "    ans = df_all.loc[df_all['Age'] <= 10, :].loc[logic, :].\\\n",
    "        groupby('Ticket')['Survived'].mean().mean()\n",
    "    print(f\"{s:>15} {ans: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Sanity check for only father groups\n",
    "index = df_all.loc[df_all['hasFather'],:].index\n",
    "df_all.loc[index,:].groupby('Ticket_num').groups.keys()\n",
    "df_all.loc[df_all['Ticket_num']==2079,:]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# See this link: https://medium.com/@ODSC/creating-if-elseif-else-variables-in-python-pandas-7900f512f0e4\n",
    "\n",
    "#Method 1. Not exactly what I want; it only identify the entry of mother, but\n",
    "#I want the result to be broadcasted to everyone in the same group.\n",
    "role = 'Mother'\n",
    "#Step 1. Identify a mother's life status\n",
    "conditions = [(df_all['Role'] != role), # 'Not applicable'\n",
    "              (df_all['Survived'].isnull()), # 'Unknown'\n",
    "              (df_all['Survived'] == 1.0), # 'Yes'\n",
    "              (df_all['Survived'] == 0.0) # 'No'\n",
    "              ]\n",
    "choices = ['Not applicable', 'Unknown', 'Yes', 'No']\n",
    "df_all['isMotherSurvived'] = np.select(conditions, choices)\n",
    "len(df_all[df_all['Role']=='Mother']['isMotherSurvived'].values) # 44 mothers on board\n",
    "\n",
    "#Step 2. \"Braodcast\" the group-specific result to other group members\n",
    "#Method 1. Use map + dictionary\n",
    "index = df_all[df_all['Role']=='Mother']['Ticket_num'] # step 1-1. get the index\n",
    "ss = pd.Series(df_all[df_all['Role']=='Mother']['isMotherSurvived'].values, index=index) # step 1-2. get the value\n",
    "df_all['isMotherSurvived'] = df_all['Ticket_num'].map(ss.to_dict()).fillna('not applicable') # step 1-3. use dictionary to update the rest\n",
    "\n",
    "#Method 2.\n",
    "#https://stackoverflow.com/questions/56708924/broadcast-value-to-dataframe-group-by-condition\n",
    "df_all['test3'] = df_all['isMotherSurvived'].where(df_all['Role'].eq('Mother'))\\\n",
    "    .groupby(df_all['Ticket_num']).transform('first').fillna('not applicable')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compact version based on the preceding uncommented methods 1 and 2.\n",
    "So, we can do it automatically based on the experimental code block above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "role = 'Mother'\n",
    "def isSurvived(df_all, role='Mother'):\n",
    "    # Step 1. Identify a mother's life status\n",
    "    conditions = [(df_all['Role'] != role),  # 'Not applicable'\n",
    "                  (df_all['Survived'].isnull()),  # 'Unknown'\n",
    "                  (df_all['Survived'] == 1.0),  # 'Yes'\n",
    "                  (df_all['Survived'] == 0.0)  # 'No'\n",
    "                  ]\n",
    "    choices = ['Not applicable', 'Unknown', 'Yes', 'No']\n",
    "    s = 'is' + role + 'Survived'\n",
    "    df_all[s] = np.select(conditions, choices)\n",
    "    df_all[s] = df_all[s].where(df_all['Role'].eq(role)) \\\n",
    "        .groupby(df_all['Ticket_num']).transform('first').fillna('not applicable')\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "roles = ['Mother', 'Father']\n",
    "for role in roles:\n",
    "    isSurvived(df_all, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: get the prefix of Cabin feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def getCabinPrefix(df):\n",
    "    # 'M' is assigned to missing values\n",
    "    df['Deck'] = df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "getCabinPrefix(df_all)\n",
    "df_all['Deck'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# def imputeCabinePrefix(df_all):\n",
    "df_all['Deck'].value_counts()\n",
    "\n",
    "# Check to see if the 2nd half of the combined table are all NaN Survived data\n",
    "# (1) iloc works with slicing that includes right endpoint.\n",
    "# (2) iloc works with index only, so even though I need 'Survived, I use it separately.\n",
    "# (3) isnull() to see if there is any missing value\n",
    "df_all.iloc[df_train.shape[0]:, ]['Survived'].isnull().all()\n",
    "\n",
    "# Cabin numbers have clusters\n",
    "df_all['Cabin'].value_counts()\n",
    "# For example, 'B57 B59 B63 B66' corresponds to five persons\n",
    "# in the Ryerson family. People in the same cabin share the same\n",
    "# Ticket_alp and Ticket_num. These three variables should be highly\n",
    "# correlated.\n",
    "df_all.loc[df_all['Cabin'] == 'B57 B59 B63 B66']\n",
    "# 'B57 B59 B63 B66' maps to Ticket_alp = 'PC', which is a much larger group.\n",
    "df_all.loc[df_all['Ticket_alp'] == 'PC']['Survived'].sum()\n",
    "\n",
    "# We may check later whether each group can be identified or associated with higher servival rate\n",
    "# We may also check to see if couples have higher survival rates\n",
    "# Check Family Ryerson. The number of SibSp and Parch might have more information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: extract names and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def getLastNameAndTitle(df):\n",
    "    # (1) https://docs.python.org/2/library/re.html\n",
    "    # (2) Why this patterns works? See the [reason](https://shorturl.at/uAEM8).\n",
    "    # (3) This pattern works as well r'^([^,]*)'\n",
    "    # See the reference [link](https://shorturl.at/dwJMS)\n",
    "    df['LastName'] = df['Name'].str.extract(r'^(.+?),')\n",
    "    df['Title'] = df['Name'].str.split(', ', expand=True)[1].\\\n",
    "        str.split('.', expand=True)[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLastNameAndTitle(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cols = ['Name', 'Title', 'LastName']\n",
    "# df_all[cols] works as well\n",
    "# colon cannot be ignored in df_all.loc[:,cols]\n",
    "df_all.loc[:, cols]\n",
    "\n",
    "# finding: People with the same surname may come from different families, for example,\n",
    "# check the group of surname 'Davies' we found Ticket #48871 corresponds\n",
    "# to three young men; ticket #33112 corresponds to one women of age 48 and\n",
    "# and a child with the same surname of age 8. However, an issue is found\n",
    "# that just using LastName is not sufficient to locate people of the same\n",
    "# family. For example, the record of the woman with Ticket #33112 shows\n",
    "# she comes with her two children. By slicing with Ticket #33112, we found the\n",
    "# woman indeed has two children whose surnames are different. So, we should only\n",
    "# use Ticket_num instead of LastName to identify people traveling together.\n",
    "df_all.loc[df_all['LastName'] == 'Davies', :].sort_values(by=['Ticket_num'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: sanity check: Is it possible to have two Mrs in a travelling group? NO.\n",
    "Trick#1: conditinal count after groupby\n",
    "The answer is no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('Ticket')['Ticket'].\\\n",
    "    apply(lambda x: (x == 'Mrs').sum()).reset_index(name='MrsCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Example of displaying group results\n",
    "gs = df_all.groupby('Ticket_num')\n",
    "print(gs.indices)  # dict\n",
    "\n",
    "# Method 1. Peek the grouped data by sampling; so only part of the data\n",
    "# grouped.groups.keys()\n",
    "# grouped.groups.items()\n",
    "# grouped.get_group(gpkey)\n",
    "import random\n",
    "sampled_group_key = random.sample(gs.groups.keys(), 100)\n",
    "group_list = list(map(lambda gpkey: gs.get_group(gpkey), sampled_group_key))\n",
    "for i, g in enumerate(group_list):\n",
    "    if len(g) > 3:\n",
    "        print(g)\n",
    "        break\n",
    "\n",
    "# Method 2. scan through the groups\n",
    "for i, g in gs.groups.items():\n",
    "    if len(g) > 4:\n",
    "        print(gs.get_group(i))\n",
    "        break\n",
    "        \n",
    "# We found: the record of the Christy indicates there are two children but only one shown.\n",
    "df_all.loc[df_all['LastName'] == 'Christy', :]        \n",
    "\n",
    "\n",
    "#Broadcasting\n",
    "#Identify travelling groups with children among which who are parents?\n",
    "# \n",
    "def addMaxParchMinSibSp(grp):\n",
    "    return pd.Series(\n",
    "        [grp['Parch'].max(), grp['SibSp'].min()],\n",
    "        ['maxParch', 'minSibSp']\n",
    "    )\n",
    "# JOIN versue MERGE [link](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "df_all = df_all.join(df_all.groupby('Ticket_num').apply(addMaxParchMinSibSp), on='Ticket_num')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# LOGICAL OPERATIONS -----------------------------------------------------------\n",
    "\n",
    "# Method 1. dataframe.where()\n",
    "# df_all['isMother'] = False\n",
    "# df_all['isMother'] = df_all['isMother'].\\\n",
    "    where((df_all['Title'] != 'Mrs') | (df_all['hasMaster'] != True), True)\n",
    "\n",
    "# Method 2. np.where()\n",
    "df_all['MotherWithMaster'] = np.where(\n",
    "    (df_all['Title'] == 'Mrs') & (df_all['hasMaster'] == True), \n",
    "    True, \n",
    "    False\n",
    ")\n",
    "df_all.loc[df_all['Title'] == 'Master', :][['Age', 'Survived']].mean()  # 5.48, 57%\n",
    "\n",
    "# Method 3. np.logical_and()\n",
    "def MWM(df):\n",
    "    return df.apply(lambda x: 1 if \n",
    "        np.logical_and(x['Title'] == 'Mrs', x['Sex'] == 'female') \n",
    "        else 0, axis=1)\n",
    "df_all['test'] = MWM(df_all)\n",
    "df_all.head(10)\n",
    "\n",
    "# BROADCASTING OPERATIONS -----------------------------------------------------------\n",
    "# Identify teams travelling with mother and children\n",
    "\n",
    "# Method 1. use `transform`\n",
    "\n",
    "temp1 = df_all.groupby(['Ticket'])['Title'].\\\n",
    "    transform(lambda x: x.eq('Master').any())\n",
    "temp2 = df_all.groupby(['Ticket'])['MotherWithMaster'].\\\n",
    "    transform(lambda x: x.eq(True).any())\n",
    "df_all['GroupWMomChild'] = temp1 & temp2\n",
    "\n",
    "# Method 2-A. use apply-turned `dictionary` and `map` IT WORKS!!\n",
    "\n",
    "# temp5 = df_all.groupby('Ticket').apply(\n",
    "#       lambda x: x['Title'].eq('Master').any() & x['MotherWithMaster'].eq(True).any())\n",
    "# df_all['GroupWMomChild_3'] = df_all['Ticket'].map(temp5)\n",
    "\n",
    "# Method 2-B. use apply and merge IT WORKS!!\n",
    "\n",
    "# temp3 = df_all.groupby(['Ticket']).apply(lambda x: x['Title'].eq('Master').any())\n",
    "# temp4 = df_all.groupby(['Ticket']).apply(lambda x: x['MotherWithMaster'].eq(True).any())\n",
    "# df_all.merge((temp3 & temp4).reset_index(), how='left').rename(columns={0: 'GroupWMomChild_2'})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: impute missing EMBARKED values using K nearest neighbors algorithm\n",
    "# They more likely board on the ship at port S -- Theory 1.\n",
    "df_all.loc[df_all['Embarked'].isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.loc[df_all['Ticket_num'].between(100000, 125000)]['Embarked'].value_counts())  # S\n",
    "print(df_all.loc[df_all['Fare'].between(60, 100)]['Embarked'].value_counts())  # S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's hard to tell which port they boarded from only based on their `Pclass` and `Fare` features.\n",
    "df_all.groupby(['Pclass',pd.cut(df_all['Fare'],range(50,100,15))])['Embarked'].\\\n",
    "    apply(lambda x: x.value_counts().nlargest(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I decide to make use of the information contained in the ticket combination:\n",
    "# Step 1. identifying data index corresponding to valid 'Embarked' data.\n",
    "index = df_all['Embarked'].isnull()\n",
    "# We are comfortable to only use three features to predict missing value.\n",
    "_dfAll = df_all.loc[:, ['Embarked', 'Pclass', 'Ticket_alp', 'Ticket_num']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. labeling and normalizing the feature matrix\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "encoder = LabelEncoder()\n",
    "minmax_scale = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2-A. encoding columns 'Pclass' and 'Ticket_alp'\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# Note below that `fit_transform()` expects a 2D array, but encoder returns a 1D array\n",
    "# So we need to reshape it.\n",
    "for i in range(1,4):\n",
    "    temp = encoder.fit_transform(_dfAll.iloc[:,i]).reshape(-1,1)\n",
    "    _dfAll.iloc[:, i] = minmax_scale.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our feature matrix consists of `Pclass`, `Ticket_alp`, and `Ticket_num`.\n",
    "_xtrain = _dfAll.loc[~index,_dfAll.columns[1:4]]\n",
    "_ytrain = encoder.fit_transform(_dfAll.loc[~index, 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. prediction with k nearest neighbors algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "knc = KNeighborsClassifier(3, weights='distance')\n",
    "trained_knc = knc.fit(_xtrain, _ytrain)\n",
    "predicted_embarked_missing = trained_knc.predict(_dfAll.loc[index, _dfAll.columns[1:4]])\n",
    "# update the missing value with what we just obtained.\n",
    "df_all.loc[index,'Embarked'] = encoder.inverse_transform(predicted_embarked_missing) # S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: Fare () Imputation based on the size of the travel team and passneger class.\n",
    "#print(df_all.loc[df_all['Fare'].isnull(),:]) # index = 973\n",
    "islice = (df_all['Pclass'] == 3)\n",
    "sns.scatterplot(x='Age', y='Fare', size= 'TeamSize', data=df_all.loc[islice,:]); plt.show()\n",
    "# impute\n",
    "df_all['Fare'] = df_all.groupby(['Pclass','TeamSize'])['Fare']\\\n",
    "    .transform(lambda x: x.fillna(x.median()))\n",
    "print(df_all.iloc[973,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Ticekt_num is more useful than LastName (aka Family)\n",
    "1. even in the same family, when women are alive, men are not necessarily alive. Ticket#19950\n",
    "2. friends or colleauges are probably in the same ticket number group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Survival rate computation\n",
    "cols = df_all.columns\n",
    "# The Davies has two children and two adults (one is maid). The youngest child is alive.\n",
    "df_all.loc[df_all['Ticket_num'] == 33112, cols]\n",
    "df_all.loc[df_all['Ticket_num'] == 2079, cols]\n",
    "df_all.loc[df_all['Ticket_num'] == 36928, cols]  # old family\n",
    "# Just check out a few of groups of size 2\n",
    "# df_all.loc[df_all['TeamSize']==7,:]['Ticket_num'].unique()\n",
    "df_all.loc[df_all['Ticket_num'] == 236853, cols]  # size of 2\n",
    "df_all.loc[df_all['Ticket_num'] == 17608, cols]  # size of 6 (all the child die)\n",
    "df_all.loc[df_all['Ticket_num'] == 3101295, cols]\n",
    "df_all.loc[df_all['Ticket_num'] == 2144, cols]\n",
    "df_all.loc[df_all['Ticket_num'] == 347742, cols]\n",
    "df_all.loc[df_all['Ticket_num'] == 347077, cols]  # team with a mother that survived\n",
    "# It appears none of them are relatives except Lam Ali and Lam Len.\n",
    "df_all.loc[df_all['Ticket_num'] == 1601, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket Number Distribution by Pclass and Embarked\n",
    "# The plot doesn't help to impute the two missing Embarked value, both of which are in Pclass = 1.\n",
    "# The only information gain is that given they share the same ticket number, they should know each\n",
    "# other and highly likely embark from either C or S together.\n",
    "g = sns.FacetGrid(df_train, col='Pclass', row='Embarked')\n",
    "g = g.map(sns.countplot, 'Ticket_num')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "g = sns.FacetGrid(df_all, col='Pclass', row='Sex')\n",
    "g = g.map(sns.countplot, 'Age')\n",
    "g.set(xticks=[range(10,70,10)])\n",
    "[plt.setp(ax.get_xticklabels(), rotation=90) for ax in g.axes.flat]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "##\n",
    "g = sns.FacetGrid(df_train, col='Pclass', row='Embarked', hue='Deck')\n",
    "g = g.map(plt.scatter, 'Age', 'Fare')\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Percentage of survived passengers by EMBARKED values -------------------------\n",
    "\n",
    "deck_embarked = df_train[['Deck', 'Embarked', 'Survived']].\\\n",
    "    groupby(['Deck', 'Embarked']).count()\n",
    "\n",
    "# solution 1\n",
    "tb1 = deck_embarked.groupby(level=1).apply(lambda x: 100 * x / float(x.sum()))\n",
    "tb1.rename(columns={'Survived': 'Passengers (%)'})\n",
    "\n",
    "# solution 2\n",
    "tb2 = 100 * deck_embarked / deck_embarked.groupby(level=1).transform('sum')\n",
    "tb2.rename(columns={'Survived': 'Passengers (%)'})\n",
    "\n",
    "# Group Selection Operation ----------------------------------------------------\n",
    "cols = ['Deck', 'Pclass']\n",
    "df_train.groupby(cols).filter(lambda x: x['Age'].\\\n",
    "    quantile(q=0.75) > 50)['Survived'].mean()\n",
    "df_train.groupby(cols).filter(lambda x: x['Age'].\\\n",
    "    quantile(q=0.75) < 30)['Survived'].mean()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add percentage bar number 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add percentage bar number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Plot training set survival distribution\n",
    "https://i.postimg.cc/25rVKwxB/1590377048.png\n",
    "https://python-graph-gallery.com/13-percent-stacked-barplot/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#Categorical variable plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Continuous variable plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#Fare binning with qcut or cut"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
